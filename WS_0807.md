



1. 완전분산 모드에서 hive 셋팅



2. hdi;



3. 각 팀 별 로그를 Hadoop에 저장하고 Hive로 분석 하시오(select, group by 등)





* 테이블 명, 컬럼 명 등 정하고
* 데이터를 하둡에 넣어두고
* hive로 select 하기





```
MariaDB 설치
    [maria]# pwd
    /root/file/maria
    # yum -y remove mariadb-libs
    # yum -y localinstall Maria*
    Installed:
      MariaDB-client.x86_64 0:10.0.15-1.el7.centos
      MariaDB-common.x86_64 0:10.0.15-1.el7.centos
      MariaDB-server.x86_64 0:10.0.15-1.el7.centos
    Complete!
    # systemctl restart mysql
    # systemctl status mysql
    # chkconfig mysql on => 서비스 상시 가동
    # firewall-config
    public - 서비스 - mysql 체크(런타임, 영구적)
    # mysql
    # mysqladmin -u root password '111111'
    # mysql -u root -p 

MariaDB [mysql]> grant all privileges on *.* to 'hive'@'localhost' identified by '111111';
MariaDB [mysql]> flush privileges;

MariaDB [mysql]> create database hive_db;
MariaDB [mysql]> grant all privileges on hive_db.* to 'hive'@'%' identified by '111111' with grant option;
MariaDB [mysql]> grant all privileges on hive_db.* to 'hive'@'localhost' identified by '111111' with grant option;
MariaDB [mysql]> flush privileges;
MariaDB [mysql]> commit;

[root@hadoop1 ~]# mysql -u hive -p
MariaDB [(none)]> use hive_db




MariaDB [mysql]> grant all privileges on hive_db.* to 'hive'@'localhost' identified by '111111' with grant option;

MariaDB [mysql]> grant all privileges on hive_db.* to 'hive'@'%' identified by '111111' with grant option;

MariaDB [mysql]> commit;

MariaDB [mysql]> select user,host from user;
+------+-----------+
| user | host      |
+------+-----------+
| hive | %         |
| root | 127.0.0.1 |
| root | ::1       |
|      | hadoop1   |
| root | hadoop1   |
|      | localhost |
| hive | localhost |
| root | localhost |
+------+-----------+

```



```
[root@hadoop1 file]# tar xvfz apache-hive-1.0.1-bin.tar.gz 
[root@hadoop1 file]# mv apache-hive-1.0.1-bin hive
[root@hadoop1 file]# cp -r hive /etc
# vi /etc/profile
HIVE_HOME=/etc/hive
export JAVA_HOME CLASSPATH TOMCAT_HOME HADOOP_HOME HIVE_HOME
PATH=.:$JAVA_HOME/bin:$TOMCAT_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$PATH
[root@hadoop1 file]# . /etc/profile

/etc/hive/conf
[conf]# vi hive-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>hive.metastore.local</name>
        <value>true</value>
        <description>controls whether to connect to remove metastore server or open a new metastore server in Hive Client JVM</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mariadb://localhost:3306/hive_db?createDatabaseIfNotExist=true</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.mariadb.jdbc.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
        <description>username to use against metastore database</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>111111</value>
        <description>password to use against metastore database</description>
    </property>
</configuration>

[root@hadoop1 file]# cp mariadb-java-client-1.3.5.jar /etc/hive/lib

# hadoop dfs -mkdir /tmp 
# hadoop dfs -chmod g+w /tmp
# hadoop dfs -mkdir /user/hive/warehouse
# hadoop dfs -chmod g+w /user/hive/warehouse

# hadoop dfs -chmod 777 /tmp/hive
# hive

hive> CREATE TABLE HDI(id INT, country STRING, hdi FLOAT, lifeex INT, mysch INT, eysch INT, gni INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;
데이터 넣고
hive> load data local inpath '/root/hdi.txt' into table HDI;
데이터 조회
hive> select id, country from hdi;


```



```
hive> CREATE TABLE S_HDI(accessDate STRING, userId STRING, userPwd STRING, userName STRING, page STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;
hive> load data local inpath '/root/shdi.txt' into table S_HDI;
hive> select 't_wiz' page, userid ID, COUNT(*) countsum from s_hdi group by userid;
OK
t_wiz	 id0	5
t_wiz	 id1	2
t_wiz	 id2	2

hive> select 'id' userid, page pp, count(*) cnt from s_hdi group by page;
OK
id	 home	1
id	 player	1
id	 stats	1
id	 t_tigers	2
id	 t_wiz	4

hive>select page pp, count(*) cnt from s_hdi group by page;
OK
 home	1
 player	1
 stats	1
 t_tigers	2
 t_wiz	4


```

